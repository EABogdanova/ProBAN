{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPSv9P8OcqlQAMRFfbKa0gy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IexcFmD3pNqL"},"outputs":[],"source":["import os\n","import math\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from pandas.core.dtypes.cast import maybe_box_datetimelike\n","from copy import deepcopy\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn.modules.container import Sequential\n","from torch.utils.data import random_split, TensorDataset, Dataset, DataLoader\n","from torchmetrics import PearsonCorrCoef, R2Score, MeanSquaredError\n","\n","import torchvision\n","from torchvision import datasets\n","\n","\n","from Model_and_trainer import CustomStructureDataset, First_CNN, ProgressPlotter, BaseTrainer\n","\n","import random\n","\n","\n","def set_random_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"]},{"cell_type":"code","source":["mean = 7.3169\n","std = 2.15\n","batch_size = 1\n","test1_dataset = CustomStructureDataset('Data/test_1.csv', str_dir = 'Data/Dataset_t1')\n","test1_dataset.train = False\n","test1_dataset.normalize = True\n","test1_dataset.mean = mean\n","test1_dataset.std = std\n","test1_dataset.transform = None\n","test1_loader = DataLoader(test1_dataset, shuffle=False, batch_size=batch_size, num_workers=2)\n","\n","test2_dataset = CustomStructureDataset('Data/test_2.csv', str_dir = 'Data/Dataset_t2')\n","test2_dataset.train = False\n","test2_dataset.normalize = True\n","test2_dataset.mean = mean\n","test2_dataset.std = std\n","test2_dataset.transform = None\n","test2_loader = DataLoader(test2_dataset, shuffle=False, batch_size=batch_size, num_workers=2)"],"metadata":{"id":"HM0G9k2ypqZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.load(f'Result Model/best_model.pt')\n","model = model.double()\n","model = model.to(device)"],"metadata":{"id":"956f0WC6qb2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the model on the test 1\n","trainer = BaseTrainer(\n","    model= model,\n","    train_dataloader = test1_loader,\n","\n","    test_dataloader= test1_loader\n",")\n","trainer.mean = mean\n","trainer.std = std\n","y_test_pred, y_test_true = trainer.get_predictions(model=model, dl=test1_loader)\n","pearson = PearsonCorrCoef()\n","corr_coef= pearson(y_test_pred, y_test_true)\n","mse = MeanSquaredError()\n","rmse = torch.sqrt(mse(y_test_pred, y_test_true))\n","print('test 1')\n","print(f'Pearson_corr: {round(corr_coef.item(), 2)}')\n","print(f'RMSE: {round(rmse.item(), 3)}')"],"metadata":{"id":"xMfm9rh2qxWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy\n","corr_df = pd.DataFrame(columns=['Pred_pKD', 'True_pKD'])\n","corr_df['Pred_pKD'] = y_test_pred\n","corr_df['True_pKD'] = y_test_true\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_colwidth', None)\n","\n","corr_df = corr_df.round(3)\n","\n","pers = scipy.stats.pearsonr(corr_df['Pred_pKD'].values, corr_df['True_pKD'].values)\n","print(f'Pearson for test 1: {pers}')"],"metadata":{"id":"ZJZaN7kjrAJE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","sns.set_context(rc={'figure.dpi': 500, 'font.size': 12})\n","fig = sns.jointplot(data=corr_df, x='True_pKD', y='Pred_pKD', palette='Set2', ylim=(2, 14), xlim=(2, 14), kind=\"reg\")"],"metadata":{"id":"qkLKbgdYrqcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checking the model on the test 2\n","y_test_pred, y_test_true = trainer.get_predictions(model=model, dl=test2_loader)\n","pearson = PearsonCorrCoef()\n","corr_coef= pearson(y_test_pred, y_test_true)\n","mse = MeanSquaredError()\n","rmse = torch.sqrt(mse(y_test_pred, y_test_true))\n","print('test 2')\n","print(f'Pearson_corr: {round(corr_coef.item(), 2)}')\n","print(f'RMSE: {round(rmse.item(), 3)}')"],"metadata":{"id":"L7N1k8WqrzcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy\n","corr_df = pd.DataFrame(columns=['Pred_pKD', 'True_pKD'])\n","corr_df['Pred_pKD'] = y_test_pred\n","corr_df['True_pKD'] = y_test_true\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_colwidth', None)\n","\n","corr_df = corr_df.round(3)\n","\n","pers = scipy.stats.pearsonr(corr_df['Pred_pKD'].values, corr_df['True_pKD'].values)\n","print(f'Pearson for test 2: {pers}')"],"metadata":{"id":"YMoXOTu8sBSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set_context(rc={'figure.dpi': 500, 'font.size': 12})\n","fig = sns.jointplot(data=corr_df, x='True_pKD', y='Pred_pKD', palette='Set2', ylim=(2, 14), xlim=(2, 14), kind=\"reg\")"],"metadata":{"id":"zaP8UMzAsHMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# features importance\n","# 0: Hydrogen bond acceptors pr1 + Hydrogen bond donors pr2\n","# 1: Hydrogen bond donors pr1 + Hydrogen bond acceptors pr2\n","# 2: Hydrogen bond acceptors pr1 + Weak hydrogen bond donors pr2\n","# 3: Weak hydrogen bond donors pr1 + Hydrogen bond acceptors pr2\n","# 4: Positive charge atoms pr1 + Negative charge atoms pr2\n","# 5: Negative charge atoms pr1 + Positive charge atoms pr2\n","# 6: Hydrophobic atoms pr1 + Hydrophobic atoms pr2\n","# 7: Carbonyl carbons pr1 + Carbonyl carbons pr2\n","# 8: Carbonyl oxygens pr1 + Carbonyl oxygens pr2\n","# 9: Aromatic atoms pr1 + Aromatic atoms pr2\n","\n","channels_names = ['HB_Ac1+Don2', 'HB_Ac2+Don1', 'HB_Ac1+Weak_Don2', 'HB_Ac2+Weak_Don1', 'Pos1+Neg2', 'Pos2+Neg1', 'Hph1+Hph2', 'Carboxy_C1+Carboxy_C2', 'Carboxy_O1+Carboxy_O2', 'Arom1+Arom2']"],"metadata":{"id":"gevrXPKxsMhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# output of weights for each input channel\n","w0 = best_model2.conv_stack[0].weight\n","w0 = pd.DataFrame(np.transpose(w0.cpu().detach().numpy(), [0, 4, 2, 3, 1]).reshape((-1, 10)),\n","                  columns=channels_names)"],"metadata":{"id":"LoletoZ6scHJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculating the average value for significant neurons\n","diff = (w0.abs() > 0.001).mean()\n","diff.sort_values(ascending=False)"],"metadata":{"id":"tRCRlZ84spSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# range between 25th and 75th percentiles\n","perc_diff = ((w0.apply(lambda x: np.percentile(x, 75))\n","             - w0.apply(lambda x: np.percentile(x, 25)))\n","             .sort_values(ascending=False))\n","\n","# plotting spreads of weights for each of 10 channels\n","fig, ax = plt.subplots(figsize=(7, 6), dpi=300)\n","\n","sns.boxplot(data=w0, fliersize=0, orient='h', ax=ax)\n","ax.set_xlim(-0.055, 0.055)\n","ax.set_xticks(np.arange(-0.04, 0.05, 0.02))\n","ax.set_ylim(10, -1)\n","\n","fig.tight_layout()\n","fig.figure.savefig(\"Result Model/model_feat_imp_1.png\")"],"metadata":{"id":"4yh_A7gcssBQ"},"execution_count":null,"outputs":[]}]}