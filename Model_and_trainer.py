# -*- coding: utf-8 -*-
"""Model_and_Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ph-1Mz11biT0dIBtpC36Rr0fRPDXMg4Z
"""

from IPython.display import clear_output
from collections import defaultdict
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
import torchvision
import os
from torch.utils.data import Dataset
from torchvision import datasets
from torch.utils.data import TensorDataset

class CustomStructureDataset(Dataset):
    def __init__(self, annotations_file, train = True, normalize = None, mean = None, std = None, transform = None,  str_dir = 'drive/MyDrive/Dataset'):
        self.str_labels = pd.read_csv(annotations_file, header=None)
        self.str_dir = str_dir
        self.train = train
        self.normalize = normalize
        self.mean = mean
        self.std = std
        self.transform = transform

    def __len__(self):
        return len(self.str_labels)

    def __getitem__(self, idx):
        str_path = os.path.join(self.str_dir, self.str_labels.iloc[idx, 1])
        structure = np.load(str_path)
        rand_num = np.random.rand(4)
        rand_k = np.random.randint(1, 4)
        if self.transform:

          if rand_num[0] < 0.5:
            structure = np.flip(structure, axis = 1)
          if rand_num[1] < 0.5:
            structure = np.flip(structure, axis = 2)
          if rand_num[2] < 0.5:
            structure = np.flip(structure, axis = 3)

#          if rand_num[0] < 0.5:
#            structure = np.rot90(structure, rand_k, (1,2))
#          if rand_num[1] < 0.5:
#            structure = np.rot90(structure, 2, (1,3))
#          if rand_num[2] < 0.5:
#            structure = np.rot90(structure, 2, (2,3))

        label = float(self.str_labels.iloc[idx, 2])
        if self.normalize:
            label = (label-self.mean)/self.std
        if self.train == True and  rand_num[3] < 0.5:
            structure = np.where(structure == 0, structure, structure*-1)
        structure = torch.from_numpy(structure.copy())
        return structure, label

import torch.nn as nn
import torch
from torch.nn.modules.container import Sequential

class First_CNN(nn.Module):

    def __init__(self):
        super().__init__()
        self.conv_stack = nn.Sequential(
            nn.Conv3d(11, 32, 7, padding=3, bias=False), # in channel=10, out=32
            nn.MaxPool3d(2), # size [32, length/2, width/2, high/2]
            nn.ReLU(),
            nn.BatchNorm3d(32),
            nn.Conv3d(32, 64, 5, padding=2, bias=False), # in channel=32, out=64
            nn.MaxPool3d(2), # size [64,length/2/2,width/2/2, high/2/2]
            nn.ReLU(),
            nn.BatchNorm3d(64),

            nn.Conv3d(64, 128, 3, padding=1, bias=False), # in channel=64, out=128
            nn.MaxPool3d(2), # size [128,length//2//2, width//2//2, high//2//2]
            nn.ReLU(),
            nn.BatchNorm3d(128),
            nn.Flatten(),
            nn.Linear(128*(81//2//2//2)*(81//2//2//2)*(41//2//2//2), 1000),
            nn.Dropout(0.3),
            nn.ReLU(),
            nn.Linear(1000, 200),
            nn.Dropout(0.3),
            nn.ReLU(),
            nn.Linear(200, 1))

    def forward(self, x):
      x = self.conv_stack(x)
      return x

from collections import defaultdict

from IPython.display import clear_output


class ProgressPlotter:

    """
    Groups contain a list of variables to output, like ["loss", "accuracy"]
    If group is None all variables will be plotted

    Title is experiment_id like "Relu_Adam_lr003"
    All new collected data binded to current title
    """

    def __init__(self, title="default", groups=None) -> None:
        self._history_dict = defaultdict(dict)
        self.set_title(title)
        self.groups = self.get_groups(groups)

    def get_groups(self, groups):
        if groups is not None:
            return self._history_dict.keys()
        if type(groups) is str:
            groups = [groups]
        return groups

    def set_title(self, title):
        for g in self._history_dict.keys():
            self._history_dict[g][title] = []  # reset data
        self.title = title

    # group e.g. "loss_val" tag e.g. "experiment_1"
    def add_scalar(self, group: str, value, tag=None) -> None:
        tag = self.title if tag is None else tag

        if not tag in self._history_dict[group]:
            self._history_dict[group][tag] = []
        self._history_dict[group][tag].append(value)

    def add_row(self, group: str, value, tag=None) -> None:
        tag = self.title if tag is None else tag
        self._history_dict[group][tag] = value

    def display_keys(self, ax, data):
        history_len = 0
        ax.grid()
        for key in data:
            ax.plot(data[key], label=key)
            history_len = max(history_len, len(data[key]))
            if len(data) > 1:
                ax.legend(loc="upper right")
            if history_len < 50:
                ax.set_xlabel("step")
                ax.set_xticks(np.arange(history_len))
                ax.set_xticklabels(np.arange(history_len))

    def display(self, groups=None):
        clear_output()
        if groups is None:
            groups = self.groups
        n_groups = len(groups)
        fig, ax = plt.subplots(1, n_groups, figsize=(48 // n_groups, 3))
        if n_groups == 1:
            ax = [ax]
        for i, g in enumerate(groups):
            ax[i].set_ylabel(g)
            self.display_keys(ax[i], self.history_dict[g])
        fig.tight_layout()
        plt.show()

    @property
    def history_dict(self):
        return dict(self._history_dict)

from copy import deepcopy

from sklearn.metrics import accuracy_score, f1_score
from tqdm.notebook import tqdm


class BaseTrainer:
    def __init__(
        self,
        model,
        train_dataloader,
        test_dataloader,
    ):
        self.model = model
        self.criterion = torch.nn.MSELoss()
        self.optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay = 0.001)
        self.num_epochs = 15
        self.mean = 7.4862
        self.std = 2.1827
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.train_dataloader = train_dataloader
        self.test_dataloader = test_dataloader
        self.best_model = None
        #self.set_score_function(PearsonCorrCoef(), "corr")
        self.set_score_function(accuracy_score, "RMSE")
        self.pp = ProgressPlotter(title="baseline", groups=["loss"])

    def set_score_function(self, score_function, title="quality metric"):
        self.score_function = score_function
        self.quality_metric = title

    def train_epoch(self):

        self.model.train()
        loss_hist = []
        for images, labels in tqdm(self.train_dataloader):
            self.optimizer.zero_grad()
            preds = self.model(images.to(self.device))
            #print(preds.shape)
            preds = torch.squeeze(preds)
            #print(preds.shape)
            loss = self.criterion(preds, labels.to(self.device))
            loss.backward()
            loss_hist.append(loss.detach().cpu())
            self.optimizer.step()
        return torch.stack(loss_hist).mean().item()

    def val_epoch(self):
        loss_hist = []
        self.model.eval()
        with torch.no_grad():
            for images, labels in tqdm(self.test_dataloader):
                preds = self.model(images.to(self.device))
                preds = torch.squeeze(preds)
                loss = self.criterion(preds, labels.to(self.device))
                loss_hist.append(loss.detach().cpu())
        return torch.stack(loss_hist).mean()

    def fit(self, verbose=True):
        self.model.to(self.device)
        best_metric_on_val = np.inf
        for epoch in tqdm(range(self.num_epochs)):
            loss_on_train = self.train_epoch()
            loss_on_val = self.val_epoch()

            metric_on_train = self.validate(on_train=True)
            metric_on_val = self.validate(on_train=False)

            if metric_on_val < best_metric_on_val:
                print("Best model updated")
                best_metric_on_val = metric_on_val
                self.save_best_model()

            self.pp.add_scalar(group="loss", value=loss_on_train, tag="train")
            self.pp.add_scalar(group="loss", value=loss_on_val, tag="val")
            self.pp.add_scalar(
                group=self.quality_metric, value=metric_on_train, tag="train"
            )
            self.pp.add_scalar(
                group=self.quality_metric, value=metric_on_val, tag="val"
            )

            if verbose:
                self.pp.display()

    def validate(self, on_train=False, using_best_model=False, **kwargs):

        dl = self.train_dataloader if on_train else self.test_dataloader
        model = self.best_model if using_best_model else self.model

        y_pred, y_true = self.get_predictions(model, dl)
        return torch.sqrt(self.score_function(y_pred, y_true, **kwargs))

    def get_predictions(self, model, dl):
        y_pred = torch.tensor([])
        y_true = torch.tensor([])

        with torch.no_grad():
            for i, data in enumerate(dl):
                img, label = data
                outputs = model(img.to(self.device))
                #_, predicted = torch.max(outputs.data, 1)
                predicted = outputs.data*self.std+self.mean
                y_pred = torch.cat((y_pred, predicted.cpu().detach()))
                y_true = torch.cat((y_true, label*self.std+self.mean))
            y_pred = torch.squeeze(y_pred)
        return y_pred, y_true

    def save_best_model(
        self,
    ):
        model_copy = deepcopy(self.model)
        self.best_model = model_copy
